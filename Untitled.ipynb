{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class parameter(object):\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "    \n",
    "    def normal(self):\n",
    "        return tf.Variable(tf.random_normal(self.shape))\n",
    "\n",
    "class layer(object):\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __str__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "    \n",
    "class lstm_layer(layer):\n",
    "    \n",
    "    def __init__(self, inputs, n_units):\n",
    "        \n",
    "        self.n_units = n_units\n",
    "        self.input_shape = inputs.shape\n",
    "        self.outputs, self.states = tf.nn.dynamic_rnn(\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(self.n_units),\n",
    "            inputs = inputs,\n",
    "            dtype = tf.float32)\n",
    "        \n",
    "    def __str__(self):\n",
    "        print('---------------[LSTM layer]---------------')\n",
    "        print('shape: ', self.input_shape, ' => ', self.outputs.shape)\n",
    "        return '|_______________[LSTM layer]_______________'\n",
    "        \n",
    "class affine_layer(layer):\n",
    "    \n",
    "    def __init__(self, inputs, shape, activation):\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.input_shape = inputs.shape\n",
    "        self.activation = activation\n",
    "        self.weights = parameter(self.shape).normal()\n",
    "        self.biases = parameter([self.shape[-1]]).normal()\n",
    "        self.outputs = self.activation(tf.add(tf.matmul(inputs, self.weights), self.biases))\n",
    "\n",
    "    def __str__(self):\n",
    "        print('---------------[Affine layer]---------------')\n",
    "        print('shape: ', self.input_shape, ' => ', self.outputs.shape)\n",
    "        return '|_______________[Affine layer]_______________'\n",
    "    \n",
    "class reshape_layer(layer):\n",
    "    \n",
    "    def __init__(self, inputs, shape):\n",
    "        \n",
    "        self.input_shape = inputs.shape\n",
    "        self.outputs = tf.reshape(inputs, shape)\n",
    "\n",
    "    def __str__(self):\n",
    "        print('---------------[Reshape layer]---------------')\n",
    "        print('shape: ', self.input_shape, ' => ', self.outputs.shape)\n",
    "        return '|_______________[Reshape layer]_______________'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_model(object):\n",
    "    \n",
    "    def __init__(self, data, output_size, n_affine = 1):\n",
    "        \n",
    "        self.frame_size = 16\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = 1e-3\n",
    "        self.data = data\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            self.input_placeholder = tf.placeholder(tf.float32, [None, None, self.frame_size])\n",
    "            self.target_placeholder = tf.placeholder(tf.float32, [None, self.output_size])\n",
    "            self.batch_size_placeholder = tf.placeholder(tf.int32)\n",
    "\n",
    "            self.layers = []\n",
    "            self.layers.append(lstm_layer(self.input_placeholder, self.frame_size))\n",
    "            self.layers.append(reshape_layer(self.layers[-1].outputs[:,-1,:], [self.batch_size_placeholder, self.frame_size]))\n",
    "            self.layers.append(affine_layer(self.layers[-1].outputs, [self.frame_size, self.output_size], tf.identity))\n",
    "\n",
    "            self.loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.layers[-1].outputs, labels=self.target_placeholder)\n",
    "            self.optimizer = tf.train.AdamOptimizer\n",
    "            self.training = self.optimizer(self.learning_rate).minimize(self.loss)\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(self.layers[-1].outputs, 1), tf.argmax(self.target_placeholder, 1)), tf.float32))\n",
    "            self.number = self.target_placeholder.shape[0]\n",
    "            \n",
    "            self.sess = tf.Session()\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "#             print(self.number)\n",
    "            \n",
    "    def train(self):\n",
    "        print(len(self.data['train_inputs']))\n",
    "        with self.graph.as_default():\n",
    "            for i in range(10):\n",
    "                accs = 0.0\n",
    "                errs = 0.0\n",
    "                ns = 0\n",
    "                for key, j in zip(self.data['train_inputs'], )\n",
    "                \n",
    "                for inputs_batch, targets_batch in zip(self.data['train_inputs'], self.data['train_targets']):\n",
    "                    print(inputs_batch)\n",
    "                    feed_dict = {self.input_placeholder:inputs_batch, self.target_placeholder:targets_batch}\n",
    "                    _, acc, err, n = self.sess.run([self.training, self.accuracy, self.loss, self.number], feed_dict)\n",
    "                    accs += acc\n",
    "                    errs += err\n",
    "                    ns += n\n",
    "                accs /= ns\n",
    "                errs /= ns\n",
    "                print('Training Epoch: %d, acc: %f, loss: %f '%(i, accs, errs))\n",
    "        \n",
    "    def record(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __str__(self):\n",
    "        for layer in self.layers:\n",
    "            print(layer)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'Placeholder:0', which has shape '(?, ?, 16)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-26aa00f01d34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train_inputs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_targets'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_affine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-af3356c64aff>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_placeholder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_placeholder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtargets_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                     \u001b[0maccs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[0merrs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'Placeholder:0', which has shape '(?, ?, 16)'"
     ]
    }
   ],
   "source": [
    "model1 = lstm_model(data={'train_inputs': data, 'train_targets': label_all[1]}, output_size=10, n_affine=1)\n",
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./multi_train_data', 'rb'))\n",
    "label_all = pickle.load(open('./multi_train_label', 'rb'))\n",
    "test_data = pickle.load(open('./multi_test_data', 'rb'))\n",
    "test_label_all = pickle.load(open('./multi_test_label', 'rb'))\n",
    "sizes = pickle.load(open('./multi_label_sizes', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
