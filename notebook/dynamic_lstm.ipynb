{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../word2vec/anouymous_train_data_200.npz', 'rb'))\n",
    "train_inputs = train_data['inputs']\n",
    "train_targets = train_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_init(name, shape):\n",
    "    return tf.get_variable(name = name, initializer = tf.truncated_normal(shape), dtype = tf.float32)\n",
    "    \n",
    "def BasicLSTMCell(n_units):\n",
    "        \n",
    "    with tf.variable_scope('basic_lstm_cell'):\n",
    "        wf = param_init('wf', [n_units, n_units])\n",
    "        bf = param_init('bf', [n_units])\n",
    "        wi = param_init('wi', [n_units, n_units])\n",
    "        bi = param_init('bi', [n_units])\n",
    "        wc = param_init('wc', [n_units, n_units])\n",
    "        bc = param_init('bc', [n_units])\n",
    "        wo = param_init('wo', [n_units, n_units])\n",
    "        bo = param_init('bo', [n_units])\n",
    "        W = tf.concat([wf, wi, wc, wo], 0)\n",
    "        B = tf.concat([bf, bi, bc, bo], 0)   \n",
    "#         c = tf.Variable(tf.zeros([n_units]), dtype = tf.float32)\n",
    "#         h = tf.reshape(inputs[:,0,:] - inputs[:,0,:], [-1, 1, n_units])\n",
    "    return W, B\n",
    "    \n",
    "def dynamic_lstm_layer(inputs, n_units, cell, batch_size, step_size):\n",
    "    \n",
    "    shape = inputs.shape.as_list()\n",
    "#     batch_size = shape[0]\n",
    "#     step_size = shape[1]\n",
    "    n_units = shape[2]\n",
    "    print('dynamic')\n",
    "#     ht = tf.reshape(inputs[:,0,:] - inputs[:,0,:], [-1, 1, n_units])\n",
    "    print('reshape')\n",
    "    h = tf.expand_dims(inputs[:,0,:], 1)\n",
    "    c = tf.Variable(tf.zeros([n_units]), dtype = tf.float32)\n",
    "    \n",
    "    def train_step(i):\n",
    "#         print('--------------')\n",
    "#         print(xt.shape)\n",
    "#         print(ct.shape)\n",
    "#         print(ht.shape)\n",
    "        nonlocal h\n",
    "#         print(h.shape)\n",
    "        xt = inputs[:, i, :]\n",
    "#         ct = \n",
    "        ht = tf.reshape(h[: -1, :], [-1, n_units])\n",
    "        ct = c\n",
    "        \n",
    "        V = tf.transpose(tf.matmul(cell[0], tf.transpose(xt, [1, 0])) + tf.matmul(cell[0], tf.transpose(ht, [1,0])), [1,0]) + cell[1]\n",
    "        ft, it, cp, ot = tf.split(V, num_or_size_splits=4, axis=1)\n",
    "        ft = tf.sigmoid(ft)\n",
    "        it = tf.sigmoid(it)\n",
    "        cp = tf.tanh(c)\n",
    "        ot = tf.sigmoid(ot)\n",
    "        new_c = tf.reshape(tf.reduce_mean(ft * tf.tile(tf.expand_dims(ct, 1), [batch_size, 1]) + it * cp, 0), [1, n_units])\n",
    "        new_h = ot * tf.tile(tf.tanh(tf.expand_dims(ct, 1)), [batch_size, 1])\n",
    "        h = tf.concat([h, tf.expand_dims(ht, 1)], 1)\n",
    "        print('finished')\n",
    "#         print(h.shape)\n",
    "        return new_c, new_h\n",
    "        \n",
    "    def iteration(cell, step_size):\n",
    "        print('iteration')\n",
    "        i = tf.constant(0)\n",
    "        ct, ht = tf.while_loop(lambda i: tf.less(i, step_size), lambda i: train_step(i), [i])\n",
    "        \n",
    "        return ct, ht\n",
    "    \n",
    "    new_c, new_ht = iteration(cell, step_size)\n",
    "    return new_c, new_ht\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic\n",
      "reshape\n",
      "iteration\n",
      "finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same number of elements. First structure: [<tf.Tensor 'while/Identity:0' shape=() dtype=int32>], second structure: [<tf.Tensor 'while/Reshape_1:0' shape=(1, 200) dtype=float32>, <tf.Tensor 'while/mul_2:0' shape=(?, 200) dtype=float32>].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-bf58146d0e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     states, outputs = dynamic_lstm_layer(inputs=inputs_placeholder, n_units=n_units, \n\u001b[1;32m---> 14\u001b[1;33m                                          cell=BasicLSTMCell(n_units), step_size=step_size, batch_size = batch_size)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#     print(outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-0a81dc620190>\u001b[0m in \u001b[0;36mdynamic_lstm_layer\u001b[1;34m(inputs, n_units, cell, batch_size, step_size)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mht\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mnew_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_ht\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_ht\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-0a81dc620190>\u001b[0m in \u001b[0;36miteration\u001b[1;34m(cell, step_size)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mht\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mless\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mht\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[0;32m   2768\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2597\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2599\u001b[1;33m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2600\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2601\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2554\u001b[0m     \u001b[1;31m# during this comparison, because inputs are typically lists and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2555\u001b[0m     \u001b[1;31m# outputs of the body are typically tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2556\u001b[1;33m     \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2558\u001b[0m     \u001b[1;31m# Store body_result to keep track of TensorArrays returned by body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[1;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[0;32m    144\u001b[0m     raise ValueError(\"The two structures don't have the same number of \"\n\u001b[0;32m    145\u001b[0m                      \u001b[1;34m\"elements. First structure: %s, second structure: %s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                      % (nest1, nest2))\n\u001b[0m\u001b[0;32m    147\u001b[0m   \u001b[0m_recursive_assert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same number of elements. First structure: [<tf.Tensor 'while/Identity:0' shape=() dtype=int32>], second structure: [<tf.Tensor 'while/Reshape_1:0' shape=(1, 200) dtype=float32>, <tf.Tensor 'while/mul_2:0' shape=(?, 200) dtype=float32>]."
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    n_units = 200\n",
    "    n_classes = 134\n",
    "    n_hidden = 128\n",
    "    \n",
    "    inputs_placeholder = tf.placeholder(tf.float32, [None, None, n_units])\n",
    "    targets_placeholder = tf.placeholder(tf.float32, [None, n_classes])\n",
    "    step_size = tf.placeholder(tf.int32)\n",
    "    batch_size = tf.placeholder(tf.int32)\n",
    "    \n",
    "    states, outputs = dynamic_lstm_layer(inputs=inputs_placeholder, n_units=n_units, \n",
    "                                         cell=BasicLSTMCell(n_units), step_size=step_size, batch_size = batch_size)\n",
    "#     print(outputs)\n",
    "    \n",
    "    w1 = tf.Variable(tf.truncated_normal([n_units, n_units]), tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([n_units]))\n",
    "    w2 = tf.Variable(tf.truncated_normal([n_units, n_classes]), tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([n_classes]))\n",
    "#     print(outputs)\n",
    "    l1 = tf.nn.relu(tf.add(tf.matmul(outputs[:, -1, :], w1), b1))\n",
    "    o1 = tf.nn.relu(tf.add(tf.matmul(l1, w2), b2))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=o1, labels=targets_placeholder))\n",
    "    loss_sum = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=o1, labels=targets_placeholder))\n",
    "    accuracy = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(o1, 1), tf.argmax(targets_placeholder, 1)), tf.float32))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    train_keys = train_inputs.keys()\n",
    "    for i in range(100):\n",
    "        accs = 0.0\n",
    "        errs = 0.0\n",
    "        n = 0\n",
    "        for key in train_keys:\n",
    "            batch_inputs = train_inputs[key]\n",
    "            batch_targets = train_targets[key]\n",
    "            size = len(batch_inputs)\n",
    "#             print(key)\n",
    "            if size == 0:\n",
    "                continue\n",
    "            feed_dict = {inputs_placeholder:batch_inputs, targets_placeholder:batch_targets, \n",
    "                         step_size:int(key.split('_')[0]), batch_size:size}\n",
    "            _, acc, err = sess.run([optimizer, accuracy, loss_sum], feed_dict = feed_dict)\n",
    "            accs += acc\n",
    "            errs += err\n",
    "            n += size\n",
    "        print('|Training Epoch%d | ACC: %f | ERR: %f | SIZE: %d |'%(i, accs/n, errs/n, n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"while_3/Exit:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i = tf.constant(0)\n",
    "c = lambda i: tf.less(i, 10)\n",
    "b = lambda i: tf.add(i, 1)\n",
    "r = tf.while_loop(c, b, [i])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-10458b795a2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'c'"
     ]
    }
   ],
   "source": [
    "def a():\n",
    "    b = 1\n",
    "    def c():\n",
    "        print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13, 200)\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs['13_0'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
