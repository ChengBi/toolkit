{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "max_batch = 200\n",
    "max_step = 40\n",
    "feature = 200\n",
    "\n",
    "def padding(filename):\n",
    "    train_data = pickle.load(open(filename, 'rb'))\n",
    "    train_inputs = train_data['inputs']\n",
    "    train_targets = train_data['targets']\n",
    "    print(train_inputs['13_0'].shape)\n",
    "    print(train_targets['13_0'].shape)\n",
    "    padded_inputs = dict()\n",
    "    padded_targets = dict()\n",
    "    for key in train_inputs.keys():\n",
    "        temp = train_inputs[key]\n",
    "        temp2 = train_targets[key]\n",
    "        if temp.shape[0] != max_batch and temp.shape[0] != 0:\n",
    "    #         print(temp.shape)\n",
    "    #         print(50-len(temp))\n",
    "    #         print(np.zeros((50 - temp.shape[0], temp.shape[1], 200)).shape)\n",
    "            temp = np.concatenate((temp, np.zeros((max_batch - temp.shape[0], temp.shape[1], feature))), 0)\n",
    "            temp2 = np.concatenate((temp2, np.zeros((max_batch - temp2.shape[0], 134))), 0)\n",
    "    #         print(temp.shape)\n",
    "            temp = np.concatenate((temp, np.zeros((max_batch, max_step - temp.shape[1], feature))), 1)\n",
    "            padded_inputs[key] = temp\n",
    "            padded_targets[key] = temp2\n",
    "        elif temp.shape[0] == max_batch and temp.shape[0] != 0:\n",
    "            temp = np.concatenate((temp, np.zeros((max_batch, max_step - temp.shape[1], feature))), 1)\n",
    "            padded_inputs[key] = temp\n",
    "            padded_targets[key] = train_targets[key]\n",
    "    print(padded_inputs['13_1'].shape)\n",
    "    print(padded_targets['13_1'].shape)\n",
    "    return padded_inputs, padded_targets\n",
    "    \n",
    "# padded_inputs, padded_targets = padding('../word2vec/anouymous_train_data_200.npz')\n",
    "# padded_test_inputs, padded_test_targets  = padding('../word2vec/anouymous_valid_data_200.npz')\n",
    "\n",
    "padded_inputs, padded_targets = pickle.load(open('../word2vec/anouymous_padded_train_data.npz', 'rb')).values()\n",
    "padded_test_inputs, padded_test_targets  = pickle.load(open('../word2vec/anouymous_padded_valid_data.npz', 'rb')).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "padded_inputs = np.reshape(padded_inputs, [670, 200, 20, 200])\n",
    "padded_targets = np.reshape(padded_targets, [670, 200, 134])\n",
    "padded_test_inputs = np.reshape(padded_test_inputs, [67, 200, 20, 200])\n",
    "padded_test_targets = np.reshape(padded_test_targets, [67, 200, 134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape), tf.float32)\n",
    "\n",
    "def lstm_layer(inputs, batch_size, step_size):\n",
    "    with tf.name_scope('lstm'):\n",
    "        shape = inputs.shape.as_list()\n",
    "        batch_size = shape[0]\n",
    "        step_size = shape[1]\n",
    "        n_units = shape[2]\n",
    "    #     print(batch_size)\n",
    "    #     print(step_size)\n",
    "\n",
    "        wf = init([n_units, n_units])\n",
    "        bf = init([n_units])\n",
    "\n",
    "        wi = init([n_units, n_units])\n",
    "        bi = init([n_units])\n",
    "\n",
    "        wc = init([n_units, n_units])\n",
    "        bc = init([n_units])\n",
    "\n",
    "        wo = init([n_units, n_units])\n",
    "        bo = init([n_units])\n",
    "\n",
    "        ht = init([batch_size, n_units])\n",
    "        ct = init([1, n_units])\n",
    "\n",
    "        ct_tiled = tf.tile(ct, [batch_size, 1])\n",
    "\n",
    "#         W = tf.transpose(tf.tile(tf.concat([wf, wi, wc, wo], 0), [1, 2]), [1, 0])\n",
    "#         B = tf.concat([bf, bi, bc, bo], 0)\n",
    "        W = tf.concat([wf, wi, wc, wo], 0)\n",
    "        B = tf.concat([bf, bi, bc, bo], 0)\n",
    "\n",
    "#         temp = (np.dot(W, x.T) + np.dot(W, h.T)).T + B\n",
    "\n",
    "#         t1, t2, t3, t4 = np.split(temp, indices_or_sections=4 ,axis=1)\n",
    "\n",
    "        for i in range(step_size):\n",
    "            xt = inputs[:, i, :]\n",
    "#             X = tf.concat([ht, xt], 1)\n",
    "#             V = tf.matmul(X, W) + B\n",
    "            V = tf.transpose(tf.matmul(W, tf.transpose(xt, [1, 0])) + tf.matmul(W, tf.transpose(ht, [1,0])), [1,0]) + B\n",
    "    \n",
    "            ft, it, c, ot = tf.split(V, num_or_size_splits=4, axis=1)\n",
    "            ft = tf.sigmoid(ft)\n",
    "            it = tf.sigmoid(it)\n",
    "            c = tf.tanh(c)\n",
    "            ot = tf.sigmoid(ot)\n",
    "            ct = tf.reshape(tf.reduce_mean(ft * ct_tiled + it * c, 0), [1, n_units])\n",
    "            ht = ot * tf.tile(tf.tanh(ct), [batch_size, 1])\n",
    "        \n",
    "    return ht, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING PROCESS START...\n",
      "#EPOCH => 0\n",
      "#Trainig Epoch: 0, ACC:0.000000, ERR:1340.867273, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 0, ACC:0.012612, ERR:813.822926, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 1\n",
      "#Trainig Epoch: 1, ACC:0.003000, ERR:584.895867, N:2000\n",
      "#EPOCH => 2\n",
      "#Trainig Epoch: 2, ACC:0.002500, ERR:239.193082, N:2000\n",
      "#EPOCH => 3\n",
      "#Trainig Epoch: 3, ACC:0.005000, ERR:139.201683, N:2000\n",
      "#EPOCH => 4\n",
      "#Trainig Epoch: 4, ACC:0.000000, ERR:114.746221, N:2000\n",
      "#EPOCH => 5\n",
      "#Trainig Epoch: 5, ACC:0.000000, ERR:104.096561, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 5, ACC:0.000373, ERR:104.460866, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 6\n",
      "#Trainig Epoch: 6, ACC:0.000000, ERR:96.488470, N:2000\n",
      "#EPOCH => 7\n",
      "#Trainig Epoch: 7, ACC:0.000000, ERR:102.071592, N:2000\n",
      "#EPOCH => 8\n",
      "#Trainig Epoch: 8, ACC:0.000000, ERR:93.553531, N:2000\n",
      "#EPOCH => 9\n",
      "#Trainig Epoch: 9, ACC:0.000000, ERR:95.352479, N:2000\n",
      "#EPOCH => 10\n",
      "#Trainig Epoch: 10, ACC:0.000000, ERR:94.219209, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 10, ACC:0.007537, ERR:96.768003, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 11\n",
      "#Trainig Epoch: 11, ACC:0.000000, ERR:95.423326, N:2000\n",
      "#EPOCH => 12\n",
      "#Trainig Epoch: 12, ACC:0.000000, ERR:92.905503, N:2000\n",
      "#EPOCH => 13\n",
      "#Trainig Epoch: 13, ACC:0.000000, ERR:94.359769, N:2000\n",
      "#EPOCH => 14\n",
      "#Trainig Epoch: 14, ACC:0.000000, ERR:92.930973, N:2000\n",
      "#EPOCH => 15\n",
      "#Trainig Epoch: 15, ACC:0.000000, ERR:93.327396, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 15, ACC:0.007463, ERR:94.721626, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 16\n",
      "#Trainig Epoch: 16, ACC:0.000000, ERR:92.894534, N:2000\n",
      "#EPOCH => 17\n",
      "#Trainig Epoch: 17, ACC:0.000000, ERR:92.891639, N:2000\n",
      "#EPOCH => 18\n",
      "#Trainig Epoch: 18, ACC:0.000000, ERR:93.640137, N:2000\n",
      "#EPOCH => 19\n",
      "#Trainig Epoch: 19, ACC:0.000000, ERR:93.392908, N:2000\n",
      "#EPOCH => 20\n",
      "#Trainig Epoch: 20, ACC:0.000000, ERR:93.134863, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 20, ACC:0.007537, ERR:93.947934, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 21\n",
      "#Trainig Epoch: 21, ACC:0.000000, ERR:93.826073, N:2000\n",
      "#EPOCH => 22\n",
      "#Trainig Epoch: 22, ACC:0.000000, ERR:92.883566, N:2000\n",
      "#EPOCH => 23\n",
      "#Trainig Epoch: 23, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 24\n",
      "#Trainig Epoch: 24, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 25\n",
      "#Trainig Epoch: 25, ACC:0.000000, ERR:92.882743, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 25, ACC:0.007612, ERR:93.665014, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 26\n",
      "#Trainig Epoch: 26, ACC:0.000000, ERR:92.882669, N:2000\n",
      "#EPOCH => 27\n",
      "#Trainig Epoch: 27, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 28\n",
      "#Trainig Epoch: 28, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 29\n",
      "#Trainig Epoch: 29, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 30\n",
      "#Trainig Epoch: 30, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 30, ACC:0.007612, ERR:93.657030, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 31\n",
      "#Trainig Epoch: 31, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 32\n",
      "#Trainig Epoch: 32, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 33\n",
      "#Trainig Epoch: 33, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 34\n",
      "#Trainig Epoch: 34, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 35\n",
      "#Trainig Epoch: 35, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 35, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 36\n",
      "#Trainig Epoch: 36, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 37\n",
      "#Trainig Epoch: 37, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 38\n",
      "#Trainig Epoch: 38, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 39\n",
      "#Trainig Epoch: 39, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 40\n",
      "#Trainig Epoch: 40, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 40, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 41\n",
      "#Trainig Epoch: 41, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 42\n",
      "#Trainig Epoch: 42, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 43\n",
      "#Trainig Epoch: 43, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 44\n",
      "#Trainig Epoch: 44, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 45\n",
      "#Trainig Epoch: 45, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 45, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 46\n",
      "#Trainig Epoch: 46, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 47\n",
      "#Trainig Epoch: 47, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 48\n",
      "#Trainig Epoch: 48, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 49\n",
      "#Trainig Epoch: 49, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 50\n",
      "#Trainig Epoch: 50, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 50, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 51\n",
      "#Trainig Epoch: 51, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 52\n",
      "#Trainig Epoch: 52, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 53\n",
      "#Trainig Epoch: 53, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 54\n",
      "#Trainig Epoch: 54, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 55\n",
      "#Trainig Epoch: 55, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 55, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 56\n",
      "#Trainig Epoch: 56, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 57\n",
      "#Trainig Epoch: 57, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 58\n",
      "#Trainig Epoch: 58, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 59\n",
      "#Trainig Epoch: 59, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 60\n",
      "#Trainig Epoch: 60, ACC:0.000000, ERR:92.882656, N:2000\n",
      "------------------------------------------------------------------\n",
      "#Testing Epoch: 60, ACC:0.007612, ERR:93.657047, N:13400\n",
      "------------------------------------------------------------------\n",
      "#EPOCH => 61\n",
      "#Trainig Epoch: 61, ACC:0.000000, ERR:92.882656, N:2000\n",
      "#EPOCH => 62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3f444a2635a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minputs_placeholder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_placeholder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;31m#, batch_size:batch_size, step_size:step_size}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0maccs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0merrs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\cheng.bi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_batch = 200\n",
    "max_step = 20\n",
    "feature = 200\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    batch_size = max_batch\n",
    "    step_size = max_step\n",
    "    \n",
    "    inputs_placeholder = tf.placeholder(tf.float32, [batch_size, step_size, feature])\n",
    "    targets_placeholder = tf.placeholder(tf.float32, [batch_size, 134])\n",
    "#     batch_size = tf.placeholder(tf.int32)\n",
    "#     step_size = tf.placeholder(tf.int32)\n",
    "    \n",
    "#     outputs, states = tf.nn.dynamic_rnn(\n",
    "#             cell = tf.contrib.rnn.BasicLSTMCell(num_units=200),\n",
    "#             inputs = inputs_placeholder,\n",
    "#             dtype = tf.float32)\n",
    "        \n",
    "#     print(outputs)\n",
    "#     print(cells)\n",
    "    outputs, states = lstm_layer(inputs_placeholder, batch_size, step_size)\n",
    "    \n",
    "    w1 = init([200, 128])\n",
    "    b1 = init([128])\n",
    "    \n",
    "#     w2 = init([128, 128])\n",
    "#     b2 = init([128])\n",
    "    \n",
    "    w3 = init([128, 134])\n",
    "    b3 = init([134])\n",
    "    \n",
    "    o1 = tf.nn.relu(tf.add(tf.matmul(outputs, w1), b1))\n",
    "#     o2 = tf.nn.relu(tf.add(tf.matmul(o1, w2), b2))\n",
    "    o3 = tf.nn.relu(tf.add(tf.matmul(o1, w3), b3))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=o3, labels=targets_placeholder))\n",
    "    sum_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=o3, labels=targets_placeholder))\n",
    "    optimizer = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "    accuracy = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(o3, 1), tf.argmax(targets_placeholder, 1)), tf.float32))\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('../outputs/', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     keys = padded_inputs.keys()\n",
    "#     test_keys = padded_test_inputs.keys()\n",
    "    print('TRAINING PROCESS START...')\n",
    "    for i in range(100):\n",
    "        accs = 0.0\n",
    "        errs = 0.0\n",
    "        n = 0\n",
    "        print('#EPOCH => %d'%(i))\n",
    "        for batch_inputs, batch_targets in zip(padded_inputs[:10], padded_targets[:10]):\n",
    "            batch_size = len(batch_inputs)\n",
    "            n += batch_size\n",
    "            feed_dict = {inputs_placeholder:batch_inputs, targets_placeholder:batch_targets}#, batch_size:batch_size, step_size:step_size}\n",
    "            _, acc, err = sess.run([optimizer, accuracy, sum_loss], feed_dict=feed_dict)\n",
    "            accs += acc\n",
    "            errs += err\n",
    "#         writer.add_summary(m, i)\n",
    "        print('#Trainig Epoch: %d, ACC:%f, ERR:%f, N:%d'%(i, accs/n, errs/n, n))\n",
    "        if i % 5 == 0:\n",
    "            accs = 0.0\n",
    "            errs = 0.0\n",
    "            n = 0\n",
    "            for batch_inputs, batch_targets in zip(padded_test_inputs[:], padded_test_targets[:]):\n",
    "                batch_size = len(batch_inputs)\n",
    "                n += batch_size\n",
    "                feed_dict = {inputs_placeholder:batch_inputs, targets_placeholder:batch_targets}#, batch_size:batch_size, step_size:step_size}\n",
    "                acc, err = sess.run([accuracy, sum_loss], feed_dict=feed_dict)\n",
    "                accs += acc\n",
    "                errs += err\n",
    "            print('------------------------------------------------------------------')\n",
    "            print('#Testing Epoch: %d, ACC:%f, ERR:%f, N:%d'%(i, accs/n, errs/n, n))\n",
    "            print('------------------------------------------------------------------')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 50\n",
    "size = 10\n",
    "# wf = np.random.random((size, size))\n",
    "# bf = np.random.random(size)\n",
    "# wi = np.random.random((size, size))\n",
    "# bi = np.random.random(size)\n",
    "# wc = np.random.random((size, size))\n",
    "# bc = np.random.random(size)\n",
    "# wo = np.random.random((size, size))\n",
    "# bo = np.random.random(size)\n",
    "# x = np.random.random((batch, size))\n",
    "# h = np.random.random((batch, size))\n",
    "wf = np.arange(size*size).reshape(size, size)\n",
    "bf = np.arange(size)\n",
    "wi = np.arange(size*size).reshape(size, size)\n",
    "bi = np.arange(size)\n",
    "wc = np.arange(size*size).reshape(size, size)\n",
    "bc = np.arange(size)\n",
    "wo = np.arange(size*size).reshape(size, size)\n",
    "bo = np.arange(size)\n",
    "x = np.arange(batch*size).reshape(batch, size)\n",
    "h = np.arange(batch*size).reshape(batch, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(50, 10)\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD8CAYAAADt/ZE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x197ed5ff198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD8CAYAAADt/ZE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x197ed5ffe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft = (np.dot(wf, x.T) + np.dot(wf, h.T)).T + bf\n",
    "it = (np.dot(wi, x.T) + np.dot(wi, h.T)).T + bi\n",
    "ot = (np.dot(wo, x.T) + np.dot(wo, h.T)).T + bo\n",
    "ct = (np.dot(wc, x.T) + np.dot(wc, h.T)).T + bc\n",
    "\n",
    "\n",
    "\n",
    "W = np.concatenate([wf, wi, wc, wo], 0)\n",
    "B = np.concatenate([bf, bi, bc, bo], 0)\n",
    "\n",
    "temp = (np.dot(W, x.T) + np.dot(W, h.T)).T + B\n",
    "\n",
    "t1, t2, t3, t4 = np.split(temp, indices_or_sections=4 ,axis=1)\n",
    "# t1 = t1.T\n",
    "# t2 = t2\n",
    "print(t1.shape)\n",
    "print(ft.shape)\n",
    "plt.imshow(np.concatenate([ft, it, ct, ot], 1))\n",
    "plt.figure()\n",
    "plt.imshow(np.concatenate([t1, t2, t3, t4], 1))\n",
    "print((ft == t1).all() and (it == t2).all() and (ot == t3).all() and (ct == t4).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
